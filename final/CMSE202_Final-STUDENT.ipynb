{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final exam (Individual)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"text-align: right;\"> &#9989; Richard Arbury</p>\n",
    "### <p style=\"text-align: right;\"> &#9989; arburyri</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSE 202 Final (Fall 2022)\n",
    "\n",
    "The goal of this final is to give you the opportunity to test out some of the skills that you've developed having now finished CMSE 202. In particular, you'll be committing and pushing repository changes to a GitHub repository, working with data to build a network graph, performing regression analysis, and classifying data using a machine learning classifier. You should find that you have all of the skills necessary to complete this exam having completed the second half of CMSE 202!\n",
    "\n",
    "You are encouraged to look through the entire exam before you get started so that you can appropriately budget your time and understand the broad goals of the exam. Once you've read through it, you'll probably want to make sure you do Part 1 first to ensure that your GitHub repository is working correctly. Let your instructor know right away if you run into issues!\n",
    "\n",
    "The exam is set up so that even if you get stuck on one part there are opportunities to get points on the other parts, so consider jumping ahead if you feel like you aren't making progress and then come back later if you have time.\n",
    "\n",
    "If you have any questions during the exam, you may ask the instructor, the TA, or the LA privately. If you are attending in-person, simply raise your hand and one of us will come over to you. If you are attending via-Zoom, please use the ask-for-help feature or privately message the instructor, the TA, or the LA. We will make any announcements or exam clarifications/corrections to the class via the following Google Document.\n",
    "\n",
    "[LINK](https://docs.google.com/document/d/16x_nbg8coBwf9hyLXRxOXAvrugkRhjeaBQJMiUwdBw8/edit?usp=sharing)\n",
    "\n",
    "**Important note about using online resources**: This exam is \"open internet\". That means that you can look up documentation, google how to accomplish certain Python tasks, etc. Being able to effectively use the internet for computational modeling and data science is a very important skill, so we want to make sure you have the opportunity to exercise that skill. **However**: The use of any person-to-person communication software is absolutely not acceptable. If you are seen accessing your email, using a chat program (e.g. Slack), or any sort of collaborative cloud storage or document software (e.g. Google Documents other than the one we will make announcements on), you will be at risk for receiving a zero on the exam.\n",
    "\n",
    "**Keep your eyes on your screen!** This exam is designed to give *you* the opportunity to show the instructor what you can do and you should hold yourself accountable for maintaining a high level of academic integrity. If any of the instructors observe suspicious behavior, you will, again, risk receiving a zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "<a id=\"toc\"></a>\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "\n",
    "0. [Part 0: Upgrade packages](#part0) (1 point)\n",
    "\n",
    "1. [Part 1: Git](#part1) (9 points)\n",
    "\n",
    "2. [Part 2: Data Preprocessing](#part2) (20 points)\n",
    "\n",
    "3. [Part 3: Regression](#part3) (15 points)\n",
    "\n",
    "4. [Part 4: Principal Component Analysis](#part4) (12 points)\n",
    "\n",
    "5. [Part 5: Support Vector Machines](#part5) (15 points)\n",
    "\n",
    "6. [Part 6: Regression Redux](#part6) (7 points)\n",
    "\n",
    "7. [Part 7: Conceptual Questions](#part7) (14 points)\n",
    "\n",
    "8. [Part 8: Conclusion](#conclusion) (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T03:50:14.352819Z",
     "start_time": "2022-12-07T03:50:14.350105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total grade for this final is 96\n"
     ]
    }
   ],
   "source": [
    "grades = [1, 9, 20, 15, 12, 15, 7, 14, 3]\n",
    "\n",
    "print(f\"The total grade for this final is {sum(grades)}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"part0\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "# Part 0: Upgrade Packages\n",
    "\n",
    "**&#9989; Question 0.1 (1 point)**: Run the cell below. Do you have the correct packages ? If not upgrade them. **You must do this in order to avoid issues in the rest of the notebook.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T03:15:16.292936Z",
     "start_time": "2022-12-07T03:15:16.283043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Sklearn version should be 1.1.3 and I have 1.1.3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Standard libraries\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Data cleaning Libraries\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.utils import resample\n",
    "# Classifier Libraries\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "\n",
    "import statsmodels.api as sm \n",
    "\n",
    "from sklearn import __version__ as sk_version\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "print(f\"Sklearn version should be 1.1.3 and I have {sk_version}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"part1\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "## Part 1: Git (9 points)\n",
    "\n",
    "For this assignment, you're going to add it to the `cmse202-f22-turnin` repository you created in class so that you can track your progress on the assignment and preserve the final version that you turn in. In order to do this you need to\n",
    "\n",
    "**&#9989; Question 1.1 (1 point)**: Navigate to your `cmse202-f22-turnin` **local** repository and create a new directory called `final` and copy this notebook in that new directory.\n",
    "\n",
    "``` bash\n",
    "mkdir final\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 1.2 (3 points)** Check the status of your local `git`.\n",
    "\n",
    "``` bash \n",
    "git status\n",
    "\n",
    "```\n",
    "Copy and paste below the output of the command.\n",
    "\n",
    "``` bash\n",
    "Your branch is up to date\n",
    "```\n",
    "\n",
    "What is the name of the branch you are in ? \n",
    "\n",
    "``` bash\n",
    "git branch\n",
    "\n",
    "main*\n",
    "```\n",
    "\n",
    "**Important:** You should be in the `main` branch. If you are not switch to the `main` branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 1.3 (3 points):**\n",
    "Add your name and GitHub username to the top of the notebook, then add and commit **ONLY** the notebook.\n",
    "\n",
    "``` bash\n",
    "git add final\n",
    "git commit -m \"final1\"\n",
    "```\n",
    "\n",
    "What is the commit message you used ?\n",
    "\n",
    "``` bash\n",
    "final1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 1.4 (1 point):** Before moving on. Check that the notebook you are working on is the correct one. Run the following cell. **Are you in the new folder you just created?** If not close this notebook and open the one in the `final` folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T20:23:32.165597Z",
     "start_time": "2022-12-05T20:23:31.986031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arburyri/cmse202-f22-turnin/final\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 1.5 (1 point):** Finally push the updated notebook to GitHub.\n",
    "\n",
    "``` bash\n",
    "git push\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: Double check you've added your Professor and your TA as collaborators to your \"turnin\" repository (you should have done this in the previous homework assignment).\n",
    "\n",
    "**Also important**: Make sure that the version of this notebook that you are working on is the same one that you just added to your repository! If you are working on a different copy of the notebook, **none of your changes will be tracked**!\n",
    "\n",
    "If everything went as intended, the file should now show up on your GitHub account in the \"`cmse202-f22-turnin`\" repository inside the `final` directory that you just created.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "<a id=\"part2\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "# Part 2. Data preprocessing (19 points)\n",
    "\n",
    "For this assignment we’re going to be working with a dataset that contains measurements of the characteristics of multiple wines. This includes things like the acidity and density. You’ll be asked to use this information, along with the machine learning tools that we’ve used in class, to determine whether the wine type is Red or White.\n",
    "\n",
    "The dataset is located at:\n",
    "`https://raw.githubusercontent.com/msu-cmse-courses/cmse202-F22-data/main/data/winequality.csv`\n",
    "\n",
    "\n",
    "**&#9989; Question 2.1 (4 points):** Do this\n",
    "\n",
    "1. Download the data and type the command you used to download the data\n",
    "\n",
    "2. Read the `winequality.csv` file into a dataframe\n",
    "\n",
    "3. Print out the **unique** labels in the `type` column. \n",
    "\n",
    "4. Display the first 10 rows of the dataset.\n",
    "\n",
    "**Note**: each row represents one data point and each column (except the `type` column) represents one feature. The `type` column corresponds to the class labels for every data point. There are two types of unique class labels in the `type` column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T20:23:35.697903Z",
     "start_time": "2022-12-05T20:23:35.694510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  381k  100  381k    0     0  75948      0  0:00:05  0:00:05 --:--:-- 86442\n"
     ]
    }
   ],
   "source": [
    "!curl -O \"https://raw.githubusercontent.com/msu-cmse-courses/cmse202-F22-data/main/data/winequality.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T20:23:36.383889Z",
     "start_time": "2022-12-05T20:23:36.381940Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['white' 'red']\n"
     ]
    }
   ],
   "source": [
    "winedf = pd.read_csv(\"winequality.csv\")\n",
    "print(winedf[\"type\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>white</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>white</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>white</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>white</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>white</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>white</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>white</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.16</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.045</td>\n",
       "      <td>30.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.47</td>\n",
       "      <td>9.6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>white</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>white</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>white</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.044</td>\n",
       "      <td>28.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.9938</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.45</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "0  white            7.0              0.27         0.36            20.7   \n",
       "1  white            6.3              0.30         0.34             1.6   \n",
       "2  white            8.1              0.28         0.40             6.9   \n",
       "3  white            7.2              0.23         0.32             8.5   \n",
       "4  white            7.2              0.23         0.32             8.5   \n",
       "5  white            8.1              0.28         0.40             6.9   \n",
       "6  white            6.2              0.32         0.16             7.0   \n",
       "7  white            7.0              0.27         0.36            20.7   \n",
       "8  white            6.3              0.30         0.34             1.6   \n",
       "9  white            8.1              0.22         0.43             1.5   \n",
       "\n",
       "   chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  \\\n",
       "0      0.045                 45.0                 170.0   1.0010  3.00   \n",
       "1      0.049                 14.0                 132.0   0.9940  3.30   \n",
       "2      0.050                 30.0                  97.0   0.9951  3.26   \n",
       "3      0.058                 47.0                 186.0   0.9956  3.19   \n",
       "4      0.058                 47.0                 186.0   0.9956  3.19   \n",
       "5      0.050                 30.0                  97.0   0.9951  3.26   \n",
       "6      0.045                 30.0                 136.0   0.9949  3.18   \n",
       "7      0.045                 45.0                 170.0   1.0010  3.00   \n",
       "8      0.049                 14.0                 132.0   0.9940  3.30   \n",
       "9      0.044                 28.0                 129.0   0.9938  3.22   \n",
       "\n",
       "   sulphates  alcohol  quality  \n",
       "0       0.45      8.8        6  \n",
       "1       0.49      9.5        6  \n",
       "2       0.44     10.1        6  \n",
       "3       0.40      9.9        6  \n",
       "4       0.40      9.9        6  \n",
       "5       0.44     10.1        6  \n",
       "6       0.47      9.6        6  \n",
       "7       0.45      8.8        6  \n",
       "8       0.49      9.5        6  \n",
       "9       0.45     11.0        6  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winedf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**&#9989; Question 2.2 (7 points):** Do the following:\n",
    "\n",
    "\n",
    "2. Replace all of the strings in your `type` column with integers based on the following:\n",
    "\n",
    "1. Drop the `NaN` in the dataset\n",
    "\n",
    "2. Drop the `quality` column\n",
    "    | original type | integer type |\n",
    "    | -------- | -------- |\n",
    "    | white | 0 |\n",
    "    | red | 1 |\n",
    "\n",
    "3. Once you've replaced the labels, display your DataFrame and confirm that it looks correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T03:22:13.098444Z",
     "start_time": "2022-12-07T03:22:13.095245Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wine = {'white': 0,'red': 1}\n",
    "winedf.type=[wine[color] for color in winedf.type]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "winedf=winedf.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6491</th>\n",
       "      <td>1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.068</td>\n",
       "      <td>28.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.99651</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.82</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>1</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "6491     1            6.8             0.620         0.08             1.9   \n",
       "6492     1            6.2             0.600         0.08             2.0   \n",
       "6494     1            6.3             0.510         0.13             2.3   \n",
       "6495     1            5.9             0.645         0.12             2.0   \n",
       "6496     1            6.0             0.310         0.47             3.6   \n",
       "\n",
       "      chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  \\\n",
       "6491      0.068                 28.0                  38.0  0.99651  3.42   \n",
       "6492      0.090                 32.0                  44.0  0.99490  3.45   \n",
       "6494      0.076                 29.0                  40.0  0.99574  3.42   \n",
       "6495      0.075                 32.0                  44.0  0.99547  3.57   \n",
       "6496      0.067                 18.0                  42.0  0.99549  3.39   \n",
       "\n",
       "      sulphates  alcohol  quality  \n",
       "6491       0.82      9.5        6  \n",
       "6492       0.58     10.5        5  \n",
       "6494       0.75     11.0        6  \n",
       "6495       0.71     10.2        5  \n",
       "6496       0.66     11.0        6  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winedf.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**&#9989; Question 2.3 (2 points):** As we've seen, when working with `scikit-learn` it can be much easier to work with the data if we have separate variables: one that stores the feature matrix and one that stores the class labels.\n",
    "\n",
    "**Do This:** Split your DataFrame so that you have two separate DataFrames: (1) one called `features`, which contains all columns of features; and (2) one called `labels`, which is a single-column dataframe that contains all of the *new* integer labels you just created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T03:22:14.395392Z",
     "start_time": "2022-12-07T03:22:14.392835Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels=winedf[\"type\"]\n",
    "features=winedf.drop([\"type\"],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Question 2.4 (1 points):** Do this:\n",
    "\n",
    "We need to scale the data. This isn't something we've talked very much about in-class, so we don't expect you to know exactly what is happening here. But it will be important for our PCA later on in the assignment. We decided to put it here so you were aware of it's existence. \n",
    "\n",
    "**Run the following bit of code below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T03:22:15.765193Z",
     "start_time": "2022-12-07T03:22:15.598135Z"
    }
   },
   "outputs": [],
   "source": [
    "features = pd.DataFrame(PowerTransformer().fit_transform(features), \n",
    "                            columns=features.columns, \n",
    "                            index=features.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Question 2.5 (3 points):** Do this:\n",
    "\n",
    "1. Split your data into a training and a testing set with a training set representing 75% of your data. For reproducibility , set the `random_state` argument to `314159`. \n",
    "\n",
    "2. Print the lengths to show you have the right number of entries for the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors, test_vectors, train_labels, test_labels=train_test_split(features, labels,test_size=0.25,random_state=314159)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5687    1\n",
       "549     0\n",
       "3958    0\n",
       "386     0\n",
       "4377    0\n",
       "       ..\n",
       "3676    0\n",
       "2409    0\n",
       "1525    0\n",
       "2839    0\n",
       "3109    0\n",
       "Name: type, Length: 4847, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5687</th>\n",
       "      <td>1.180898</td>\n",
       "      <td>1.597531</td>\n",
       "      <td>-1.034481</td>\n",
       "      <td>-0.269389</td>\n",
       "      <td>1.641557</td>\n",
       "      <td>-0.414082</td>\n",
       "      <td>0.095580</td>\n",
       "      <td>1.981054e-15</td>\n",
       "      <td>-0.786383</td>\n",
       "      <td>0.106812</td>\n",
       "      <td>-1.062959</td>\n",
       "      <td>-0.934513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>0.183024</td>\n",
       "      <td>0.989431</td>\n",
       "      <td>2.130568</td>\n",
       "      <td>1.183128</td>\n",
       "      <td>0.050064</td>\n",
       "      <td>2.061240</td>\n",
       "      <td>1.311481</td>\n",
       "      <td>1.752071e-15</td>\n",
       "      <td>-0.312812</td>\n",
       "      <td>-0.787425</td>\n",
       "      <td>-1.857856</td>\n",
       "      <td>-0.934513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>-1.688323</td>\n",
       "      <td>-1.212892</td>\n",
       "      <td>-0.883093</td>\n",
       "      <td>0.790484</td>\n",
       "      <td>-0.060267</td>\n",
       "      <td>0.452918</td>\n",
       "      <td>-0.060550</td>\n",
       "      <td>-1.353084e-16</td>\n",
       "      <td>0.320015</td>\n",
       "      <td>-0.891558</td>\n",
       "      <td>-0.828375</td>\n",
       "      <td>0.232781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>-2.744623</td>\n",
       "      <td>-1.415067</td>\n",
       "      <td>1.600348</td>\n",
       "      <td>-1.096645</td>\n",
       "      <td>-1.682639</td>\n",
       "      <td>-0.218705</td>\n",
       "      <td>0.026396</td>\n",
       "      <td>-2.515349e-15</td>\n",
       "      <td>1.553235</td>\n",
       "      <td>-1.109150</td>\n",
       "      <td>0.412081</td>\n",
       "      <td>1.333569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4377</th>\n",
       "      <td>-0.506894</td>\n",
       "      <td>-2.021698</td>\n",
       "      <td>-0.297545</td>\n",
       "      <td>-0.406910</td>\n",
       "      <td>-0.916976</td>\n",
       "      <td>0.244951</td>\n",
       "      <td>-0.667954</td>\n",
       "      <td>-1.998401e-15</td>\n",
       "      <td>0.009768</td>\n",
       "      <td>1.497614</td>\n",
       "      <td>0.809209</td>\n",
       "      <td>0.232781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3676</th>\n",
       "      <td>-2.183349</td>\n",
       "      <td>-0.011794</td>\n",
       "      <td>-0.085707</td>\n",
       "      <td>-1.365093</td>\n",
       "      <td>-1.409200</td>\n",
       "      <td>-0.156551</td>\n",
       "      <td>-0.360424</td>\n",
       "      <td>-4.669876e-15</td>\n",
       "      <td>0.618537</td>\n",
       "      <td>-0.998762</td>\n",
       "      <td>2.031810</td>\n",
       "      <td>1.333569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409</th>\n",
       "      <td>0.094017</td>\n",
       "      <td>-0.902718</td>\n",
       "      <td>-0.226484</td>\n",
       "      <td>-0.359305</td>\n",
       "      <td>-0.994275</td>\n",
       "      <td>-0.282281</td>\n",
       "      <td>-0.043118</td>\n",
       "      <td>-3.365364e-16</td>\n",
       "      <td>0.849298</td>\n",
       "      <td>0.905976</td>\n",
       "      <td>-0.105800</td>\n",
       "      <td>-2.184624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>0.183024</td>\n",
       "      <td>-0.274594</td>\n",
       "      <td>2.637708</td>\n",
       "      <td>1.357144</td>\n",
       "      <td>-0.767703</td>\n",
       "      <td>0.966426</td>\n",
       "      <td>0.721765</td>\n",
       "      <td>2.036565e-15</td>\n",
       "      <td>-1.141285</td>\n",
       "      <td>-0.587942</td>\n",
       "      <td>-1.857856</td>\n",
       "      <td>-0.934513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2839</th>\n",
       "      <td>-1.389925</td>\n",
       "      <td>-0.787276</td>\n",
       "      <td>-0.155873</td>\n",
       "      <td>-1.691600</td>\n",
       "      <td>-0.994275</td>\n",
       "      <td>0.350615</td>\n",
       "      <td>-0.432035</td>\n",
       "      <td>-3.341077e-15</td>\n",
       "      <td>-0.445440</td>\n",
       "      <td>-1.460634</td>\n",
       "      <td>0.642054</td>\n",
       "      <td>1.333569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3109</th>\n",
       "      <td>-0.092963</td>\n",
       "      <td>-0.011794</td>\n",
       "      <td>0.326283</td>\n",
       "      <td>0.270478</td>\n",
       "      <td>0.256022</td>\n",
       "      <td>0.190760</td>\n",
       "      <td>1.488508</td>\n",
       "      <td>3.157197e-16</td>\n",
       "      <td>1.128132</td>\n",
       "      <td>0.470314</td>\n",
       "      <td>0.076128</td>\n",
       "      <td>-2.184624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4847 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "5687       1.180898          1.597531    -1.034481       -0.269389   1.641557   \n",
       "549        0.183024          0.989431     2.130568        1.183128   0.050064   \n",
       "3958      -1.688323         -1.212892    -0.883093        0.790484  -0.060267   \n",
       "386       -2.744623         -1.415067     1.600348       -1.096645  -1.682639   \n",
       "4377      -0.506894         -2.021698    -0.297545       -0.406910  -0.916976   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "3676      -2.183349         -0.011794    -0.085707       -1.365093  -1.409200   \n",
       "2409       0.094017         -0.902718    -0.226484       -0.359305  -0.994275   \n",
       "1525       0.183024         -0.274594     2.637708        1.357144  -0.767703   \n",
       "2839      -1.389925         -0.787276    -0.155873       -1.691600  -0.994275   \n",
       "3109      -0.092963         -0.011794     0.326283        0.270478   0.256022   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide       density        pH  \\\n",
       "5687            -0.414082              0.095580  1.981054e-15 -0.786383   \n",
       "549              2.061240              1.311481  1.752071e-15 -0.312812   \n",
       "3958             0.452918             -0.060550 -1.353084e-16  0.320015   \n",
       "386             -0.218705              0.026396 -2.515349e-15  1.553235   \n",
       "4377             0.244951             -0.667954 -1.998401e-15  0.009768   \n",
       "...                   ...                   ...           ...       ...   \n",
       "3676            -0.156551             -0.360424 -4.669876e-15  0.618537   \n",
       "2409            -0.282281             -0.043118 -3.365364e-16  0.849298   \n",
       "1525             0.966426              0.721765  2.036565e-15 -1.141285   \n",
       "2839             0.350615             -0.432035 -3.341077e-15 -0.445440   \n",
       "3109             0.190760              1.488508  3.157197e-16  1.128132   \n",
       "\n",
       "      sulphates   alcohol   quality  \n",
       "5687   0.106812 -1.062959 -0.934513  \n",
       "549   -0.787425 -1.857856 -0.934513  \n",
       "3958  -0.891558 -0.828375  0.232781  \n",
       "386   -1.109150  0.412081  1.333569  \n",
       "4377   1.497614  0.809209  0.232781  \n",
       "...         ...       ...       ...  \n",
       "3676  -0.998762  2.031810  1.333569  \n",
       "2409   0.905976 -0.105800 -2.184624  \n",
       "1525  -0.587942 -1.857856 -0.934513  \n",
       "2839  -1.460634  0.642054  1.333569  \n",
       "3109   0.470314  0.076128 -2.184624  \n",
       "\n",
       "[4847 rows x 12 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1780    0\n",
       "2494    0\n",
       "4006    0\n",
       "5821    1\n",
       "1551    0\n",
       "       ..\n",
       "6322    1\n",
       "4648    0\n",
       "1217    0\n",
       "6202    1\n",
       "3626    0\n",
       "Name: type, Length: 1616, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>1.062025</td>\n",
       "      <td>-1.415067</td>\n",
       "      <td>-0.015980</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>0.155415</td>\n",
       "      <td>0.966426</td>\n",
       "      <td>0.621750</td>\n",
       "      <td>4.198031e-16</td>\n",
       "      <td>0.197356</td>\n",
       "      <td>-1.222842</td>\n",
       "      <td>-0.501115</td>\n",
       "      <td>-0.934513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>0.512081</td>\n",
       "      <td>0.069326</td>\n",
       "      <td>-0.586437</td>\n",
       "      <td>1.371692</td>\n",
       "      <td>0.256022</td>\n",
       "      <td>-0.482530</td>\n",
       "      <td>0.436934</td>\n",
       "      <td>2.182282e-15</td>\n",
       "      <td>-0.312812</td>\n",
       "      <td>-0.052782</td>\n",
       "      <td>-0.607085</td>\n",
       "      <td>-2.184624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>-2.011536</td>\n",
       "      <td>-1.705366</td>\n",
       "      <td>0.053315</td>\n",
       "      <td>-0.456443</td>\n",
       "      <td>-0.767703</td>\n",
       "      <td>-1.303516</td>\n",
       "      <td>-1.138563</td>\n",
       "      <td>-3.733125e-15</td>\n",
       "      <td>-1.141285</td>\n",
       "      <td>0.537446</td>\n",
       "      <td>1.568890</td>\n",
       "      <td>0.232781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5821</th>\n",
       "      <td>-0.191216</td>\n",
       "      <td>0.735284</td>\n",
       "      <td>-0.015980</td>\n",
       "      <td>1.016439</td>\n",
       "      <td>1.324104</td>\n",
       "      <td>-0.095734</td>\n",
       "      <td>-1.255789</td>\n",
       "      <td>2.112893e-15</td>\n",
       "      <td>1.017851</td>\n",
       "      <td>0.905976</td>\n",
       "      <td>-0.200552</td>\n",
       "      <td>0.232781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>-0.398015</td>\n",
       "      <td>-1.148268</td>\n",
       "      <td>3.942038</td>\n",
       "      <td>-1.365093</td>\n",
       "      <td>1.963874</td>\n",
       "      <td>0.878436</td>\n",
       "      <td>0.267167</td>\n",
       "      <td>-6.106227e-16</td>\n",
       "      <td>-0.786383</td>\n",
       "      <td>-2.122312</td>\n",
       "      <td>-1.857856</td>\n",
       "      <td>0.232781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6322</th>\n",
       "      <td>1.000050</td>\n",
       "      <td>-0.369192</td>\n",
       "      <td>0.393501</td>\n",
       "      <td>-1.180779</td>\n",
       "      <td>1.105978</td>\n",
       "      <td>-1.514797</td>\n",
       "      <td>-1.707296</td>\n",
       "      <td>1.637579e-15</td>\n",
       "      <td>0.320015</td>\n",
       "      <td>1.223164</td>\n",
       "      <td>-0.716132</td>\n",
       "      <td>0.232781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4648</th>\n",
       "      <td>-0.292846</td>\n",
       "      <td>1.541740</td>\n",
       "      <td>-0.733766</td>\n",
       "      <td>-0.979073</td>\n",
       "      <td>1.906854</td>\n",
       "      <td>0.648531</td>\n",
       "      <td>2.074711</td>\n",
       "      <td>-4.891920e-16</td>\n",
       "      <td>-0.648372</td>\n",
       "      <td>0.470314</td>\n",
       "      <td>-1.062959</td>\n",
       "      <td>-0.934513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>0.803149</td>\n",
       "      <td>1.541740</td>\n",
       "      <td>0.460320</td>\n",
       "      <td>1.327101</td>\n",
       "      <td>2.468448</td>\n",
       "      <td>-0.218705</td>\n",
       "      <td>1.759528</td>\n",
       "      <td>2.702699e-15</td>\n",
       "      <td>-1.896036</td>\n",
       "      <td>-0.221340</td>\n",
       "      <td>-1.185570</td>\n",
       "      <td>-0.934513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6202</th>\n",
       "      <td>0.512081</td>\n",
       "      <td>1.942902</td>\n",
       "      <td>-0.733766</td>\n",
       "      <td>-0.561850</td>\n",
       "      <td>1.396337</td>\n",
       "      <td>-0.414082</td>\n",
       "      <td>-0.815851</td>\n",
       "      <td>5.377643e-16</td>\n",
       "      <td>-0.580189</td>\n",
       "      <td>-0.587942</td>\n",
       "      <td>-1.185570</td>\n",
       "      <td>-0.934513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3626</th>\n",
       "      <td>0.002067</td>\n",
       "      <td>-0.096054</td>\n",
       "      <td>0.122182</td>\n",
       "      <td>-1.691600</td>\n",
       "      <td>-0.489288</td>\n",
       "      <td>-0.482530</td>\n",
       "      <td>0.061029</td>\n",
       "      <td>-2.595146e-15</td>\n",
       "      <td>0.009768</td>\n",
       "      <td>-0.052782</td>\n",
       "      <td>0.855207</td>\n",
       "      <td>-0.934513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1616 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "1780       1.062025         -1.415067    -0.015980        0.484375   0.155415   \n",
       "2494       0.512081          0.069326    -0.586437        1.371692   0.256022   \n",
       "4006      -2.011536         -1.705366     0.053315       -0.456443  -0.767703   \n",
       "5821      -0.191216          0.735284    -0.015980        1.016439   1.324104   \n",
       "1551      -0.398015         -1.148268     3.942038       -1.365093   1.963874   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "6322       1.000050         -0.369192     0.393501       -1.180779   1.105978   \n",
       "4648      -0.292846          1.541740    -0.733766       -0.979073   1.906854   \n",
       "1217       0.803149          1.541740     0.460320        1.327101   2.468448   \n",
       "6202       0.512081          1.942902    -0.733766       -0.561850   1.396337   \n",
       "3626       0.002067         -0.096054     0.122182       -1.691600  -0.489288   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide       density        pH  \\\n",
       "1780             0.966426              0.621750  4.198031e-16  0.197356   \n",
       "2494            -0.482530              0.436934  2.182282e-15 -0.312812   \n",
       "4006            -1.303516             -1.138563 -3.733125e-15 -1.141285   \n",
       "5821            -0.095734             -1.255789  2.112893e-15  1.017851   \n",
       "1551             0.878436              0.267167 -6.106227e-16 -0.786383   \n",
       "...                   ...                   ...           ...       ...   \n",
       "6322            -1.514797             -1.707296  1.637579e-15  0.320015   \n",
       "4648             0.648531              2.074711 -4.891920e-16 -0.648372   \n",
       "1217            -0.218705              1.759528  2.702699e-15 -1.896036   \n",
       "6202            -0.414082             -0.815851  5.377643e-16 -0.580189   \n",
       "3626            -0.482530              0.061029 -2.595146e-15  0.009768   \n",
       "\n",
       "      sulphates   alcohol   quality  \n",
       "1780  -1.222842 -0.501115 -0.934513  \n",
       "2494  -0.052782 -0.607085 -2.184624  \n",
       "4006   0.537446  1.568890  0.232781  \n",
       "5821   0.905976 -0.200552  0.232781  \n",
       "1551  -2.122312 -1.857856  0.232781  \n",
       "...         ...       ...       ...  \n",
       "6322   1.223164 -0.716132  0.232781  \n",
       "4648   0.470314 -1.062959 -0.934513  \n",
       "1217  -0.221340 -1.185570 -0.934513  \n",
       "6202  -0.587942 -1.185570 -0.934513  \n",
       "3626  -0.052782  0.855207 -0.934513  \n",
       "\n",
       "[1616 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository! (2 points)**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"Committing Part 2\", and push the changes to GitHub.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part3\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "# Part 3. Regression (15 Points)\n",
    "\n",
    "**&#9989; Question 3.1.1 (3 points):**\n",
    "Let's start making some prediction. \n",
    "\n",
    "1. Make a Logistic Regression model using `statsmodels` for predicting the type of wine. \n",
    "\n",
    "2. Print out the summary of your model fits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.039545\n",
      "         Iterations: 35\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   type   No. Observations:                 4847\n",
      "Model:                          Logit   Df Residuals:                     4835\n",
      "Method:                           MLE   Df Model:                           11\n",
      "Date:                Wed, 14 Dec 2022   Pseudo R-squ.:                  0.9291\n",
      "Time:                        21:33:52   Log-Likelihood:                -191.68\n",
      "converged:                      False   LL-Null:                       -2704.8\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "const                   -4.5133      0.287    -15.702      0.000      -5.077      -3.950\n",
      "fixed acidity            1.4086      0.216      6.532      0.000       0.986       1.831\n",
      "volatile acidity         2.0186      0.206      9.811      0.000       1.615       2.422\n",
      "citric acid             -0.1566      0.169     -0.927      0.354      -0.488       0.174\n",
      "residual sugar          -0.2889      0.239     -1.207      0.228      -0.758       0.180\n",
      "chlorides                1.8537      0.204      9.081      0.000       1.454       2.254\n",
      "free sulfur dioxide      0.9709      0.276      3.517      0.000       0.430       1.512\n",
      "total sulfur dioxide    -3.2489      0.309    -10.530      0.000      -3.854      -2.644\n",
      "density              -2.343e-06   1.34e+14  -1.75e-20      1.000   -2.62e+14    2.62e+14\n",
      "pH                       1.3151      0.216      6.091      0.000       0.892       1.738\n",
      "sulphates                1.2462      0.207      6.034      0.000       0.841       1.651\n",
      "alcohol                  0.1510      0.239      0.631      0.528      -0.318       0.620\n",
      "quality                  0.0939      0.181      0.518      0.605      -0.262       0.450\n",
      "========================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.27 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "logit_model = sm.Logit(train_labels, sm.add_constant(train_vectors))\n",
    "result = logit_model.fit()\n",
    "print(result.summary() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Question 3.1.2 (2 points):** Further examine the results by  \n",
    "\n",
    "1. printing a classification report\n",
    "2. making a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T03:26:35.328300Z",
     "start_time": "2022-12-07T03:26:35.326261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.039545\n",
      "         Iterations: 35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1216\n",
      "           1       0.99      0.99      0.99       400\n",
      "\n",
      "    accuracy                           0.99      1616\n",
      "   macro avg       0.99      0.99      0.99      1616\n",
      "weighted avg       0.99      0.99      0.99      1616\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "logit_model = sm.Logit(train_labels, sm.add_constant(train_vectors)).fit()\n",
    "const = sm.add_constant(test_vectors)\n",
    "\n",
    "predicted=logit_model.predict(const)\n",
    "predicted_labels=list(map(round,predicted))\n",
    "print(classification_report(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[1211    5]\n",
      " [   5  395]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(test_labels, predicted_labels)\n",
    "print (\"Confusion Matrix : \\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Question 3.2.1 (3 points):** Make an reduced Logistic Regression model for predicting the type of wine that uses just three parameters (two from the dataset + a constant). Print out the summary of your model fits.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1=winedf[\"type\"]\n",
    "features1=winedf[[\"quality\",\"citric acid\",\"chlorides\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.253597\n",
      "         Iterations 8\n"
     ]
    }
   ],
   "source": [
    "features1 = pd.DataFrame(PowerTransformer().fit_transform(features1), \n",
    "                            columns=features1.columns, \n",
    "                            index=features1.index)\n",
    "train_vectors1, test_vectors1, train_labels1, test_labels1=train_test_split(features1, labels1,test_size=0.25,random_state=314159)\n",
    "\n",
    "logit_model1 = sm.Logit(train_labels1, sm.add_constant(train_vectors1)).fit()\n",
    "const1 = sm.add_constant(test_vectors1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Question 3.2.2 (2 points):** Same as above, examine the results of your reduced model by printing a classification report and a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T03:29:01.144438Z",
     "start_time": "2022-12-07T03:29:01.142337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95      1216\n",
      "           1       0.85      0.81      0.83       400\n",
      "\n",
      "    accuracy                           0.92      1616\n",
      "   macro avg       0.89      0.88      0.89      1616\n",
      "weighted avg       0.92      0.92      0.92      1616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted1=logit_model1.predict(const1)\n",
    "predicted_labels1=list(map(round,predicted1))\n",
    "print(classification_report(test_labels1, predicted_labels1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[1160   56]\n",
      " [  78  322]]\n"
     ]
    }
   ],
   "source": [
    "cm1 = confusion_matrix(test_labels1, predicted_labels1)\n",
    "print (\"Confusion Matrix : \\n\", cm1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Question 3.3 (3 points):** How did you pick the best parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I just looked as the lowest standard error\n",
    "\n",
    "Alternatively, auxillary regressions would be more accurate but theres a lot of varibles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository! (2 points)**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"Committing Part 3\", and push the changes to GitHub.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"part4\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "# Part 4. Principal Component Analysis (12 points)\n",
    "\n",
    "The full model uses all 12 features to predict the results. In many cases, we might need to see how close we can get with fewer features. Instead of simply removing features, we will use a Principal Component Analysis (PCA) to determine the combined features that contribute the most to the model (through their accounted variance).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**&#9989; Question 4.1 (5 points):** Run a Principle Component Analysis (PCA)\n",
    "\n",
    "Since we only have 12 features to start with, let's see how well we can do if we try to aggressively reduce the feature count and use only **2** principle components. \n",
    "\n",
    "1. Using `PCA()` and the associated methods, run a principle component analysis on your `features` dataset using only 2 components. \n",
    "\n",
    "2. Transform the dataset into a new dataset and call it `pca_features`. \n",
    "\n",
    "3. Print the `explained_variance_ratio_` and its sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T03:32:35.543453Z",
     "start_time": "2022-12-07T03:32:35.541284Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26372782 0.22443511]\n",
      "48.81629363475885\n"
     ]
    }
   ],
   "source": [
    "winedf.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "winedf=winedf.dropna()\n",
    "features=winedf.drop([\"type\"],axis=1)\n",
    "features = pd.DataFrame(PowerTransformer().fit_transform(features), \n",
    "                            columns=features.columns, \n",
    "                            index=features.index)\n",
    "\n",
    "x = features.values\n",
    "\n",
    "y = winedf.loc[:,['type']].values\n",
    "\n",
    "x = StandardScaler().fit_transform(x)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "Components = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = Components)\n",
    "pca_features = pd.concat([principalDf, winedf[['type']]], axis = 1)\n",
    "print(pca.explained_variance_ratio_)\n",
    "total_variance = np.sum(pca.explained_variance_ratio_)*100\n",
    "print(total_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "&#9989; **Question 4.1.1 (2 points):** What is the **total** explained variance ratio captured by the 2 principle components? (just quote the number) How well do you think a model with these many features will perform? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "48.8% of variance was explained. \n",
    "\n",
    "The model will not preform well, I think it bottle necks with 12 features and two components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Question 4.2 (3 points):** Do the following:\n",
    "\n",
    "1. Split your new features (`pca_features`) and corresponding labels (the labels are the same as before) into a training and a testing set, with the training set representing 75% of your data. For reproducibility, set the `random_state` argument to `314159`. \n",
    "\n",
    "2. Print the lengths to show you have the right number of entries.\n",
    "\n",
    "Basically do the same you have done in Q2.5 but with the `pca_features` dataset now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T03:34:12.203423Z",
     "start_time": "2022-12-07T03:34:12.200976Z"
    }
   },
   "outputs": [],
   "source": [
    "labels=pca_features['type']\n",
    "pca_features=pca_features.drop(['type'],axis=1)\n",
    "##train_vectors, test_vectors, train_labels, test_labels=train_test_split(pca_features,labels,test_size=0.25,random_state=314159)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors2, test_vectors2, train_labels2, test_labels2=train_test_split(pca_features,labels,test_size=0.25,random_state=314159)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3939</th>\n",
       "      <td>0.750764</td>\n",
       "      <td>0.056581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6456</th>\n",
       "      <td>2.385134</td>\n",
       "      <td>-2.716573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036</th>\n",
       "      <td>-1.831009</td>\n",
       "      <td>-1.350157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3940</th>\n",
       "      <td>-1.422997</td>\n",
       "      <td>0.190410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5198</th>\n",
       "      <td>3.202605</td>\n",
       "      <td>1.065750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650</th>\n",
       "      <td>-2.208239</td>\n",
       "      <td>-4.047616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>0.240979</td>\n",
       "      <td>-0.138694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>-1.270813</td>\n",
       "      <td>3.319462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2815</th>\n",
       "      <td>-2.150345</td>\n",
       "      <td>-2.585743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3083</th>\n",
       "      <td>0.114721</td>\n",
       "      <td>1.019750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4871 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1\n",
       "3939  0.750764  0.056581\n",
       "6456  2.385134 -2.716573\n",
       "3036 -1.831009 -1.350157\n",
       "3940 -1.422997  0.190410\n",
       "5198  3.202605  1.065750\n",
       "...        ...       ...\n",
       "3650 -2.208239 -4.047616\n",
       "2385  0.240979 -0.138694\n",
       "1501 -1.270813  3.319462\n",
       "2815 -2.150345 -2.585743\n",
       "3083  0.114721  1.019750\n",
       "\n",
       "[4871 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vectors2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>component 1</th>\n",
       "      <th>component 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2821</th>\n",
       "      <td>-1.128734</td>\n",
       "      <td>-1.074800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5480</th>\n",
       "      <td>1.946507</td>\n",
       "      <td>1.319697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>0.471140</td>\n",
       "      <td>-1.038912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>-1.600458</td>\n",
       "      <td>1.729770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3522</th>\n",
       "      <td>-1.197440</td>\n",
       "      <td>-1.281387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>0.301048</td>\n",
       "      <td>-0.604543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2901</th>\n",
       "      <td>-2.540532</td>\n",
       "      <td>-0.307936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2033</th>\n",
       "      <td>-0.626591</td>\n",
       "      <td>-1.496974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>-1.374908</td>\n",
       "      <td>2.049971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5802</th>\n",
       "      <td>2.056961</td>\n",
       "      <td>0.105271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1624 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      component 1  component 2\n",
       "2821    -1.128734    -1.074800\n",
       "5480     1.946507     1.319697\n",
       "2010     0.471140    -1.038912\n",
       "542     -1.600458     1.729770\n",
       "3522    -1.197440    -1.281387\n",
       "...           ...          ...\n",
       "1249     0.301048    -0.604543\n",
       "2901    -2.540532    -0.307936\n",
       "2033    -0.626591    -1.496974\n",
       "317     -1.374908     2.049971\n",
       "5802     2.056961     0.105271\n",
       "\n",
       "[1624 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vectors2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3939    0.0\n",
       "6456    1.0\n",
       "3036    0.0\n",
       "3940    0.0\n",
       "5198    1.0\n",
       "       ... \n",
       "3650    0.0\n",
       "2385    0.0\n",
       "1501    0.0\n",
       "2815    0.0\n",
       "3083    0.0\n",
       "Name: type, Length: 4871, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2821    0.0\n",
       "5480    1.0\n",
       "2010    0.0\n",
       "542     0.0\n",
       "3522    0.0\n",
       "       ... \n",
       "1249    0.0\n",
       "2901    0.0\n",
       "2033    0.0\n",
       "317     0.0\n",
       "5802    1.0\n",
       "Name: type, Length: 1624, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository! (2 points)**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"Committing Part 4\".\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "<a id=\"part5\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "# Part 5. Support Vector Machine (15 points)\n",
    "\n",
    "Let's see how an SVM performs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**&#9989; Question 5.1 (9 points):** Do the following:\n",
    "\n",
    "1. Build a `SVC` model with a `linear` kernel. (2 points), \n",
    "\n",
    "2. Use `GridSearchCV` to find the best `C` parameter from this list: `'C':[0.0001, 0.001, 0.1, 1, 10]`, (2 points)\n",
    "  \n",
    "3. **Fit** the above model on the training set and **print** the best estimator (2 points)\n",
    "\n",
    "4. Use your best estimator on the test dataset to make prediction. (1 point)\n",
    "\n",
    "5. Print a [classification report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html), based on its performance on the testing dataset. (1 point)\n",
    "\n",
    "6. Print the [confusion matrix](https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py) on the testing dataset  (1 point)\n",
    "\n",
    "**Note:** You can set the `GridSearchCV` keyword argument `n_jobs = -1` to speed things up (this allows the process to run on multiple cores.)\n",
    "\n",
    "**Note:** If `GridSearchCV` is slow you can use the built-in model `LinearSVC` in `sklearn`. This is the same as `SVC(kernel = 'linear')` but it is faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = {'white': 0,'red': 1}\n",
    "winedf=winedf.dropna()\n",
    "labels=winedf[\"type\"]\n",
    "features=winedf.drop([\"type\"],axis=1)\n",
    "Xtrain, Xtest, Ytrain, Ytest=train_test_split(features,labels,test_size=0.25,random_state=314159)\n",
    "\n",
    "scaler=StandardScaler()\n",
    "\n",
    "scalerXtrain=scaler.fit_transform(Xtrain)\n",
    "scalerXtest=scaler.transform(Xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T03:35:07.832760Z",
     "start_time": "2022-12-07T03:35:07.829838Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {'kernel':('linear', 'rbf'), 'C':[0.0001, 0.001, 0.1, 1, 10]}\n",
    "my_model=svm.SVC()\n",
    "clf = GridSearchCV(my_model, parameters)\n",
    "fitted=clf.fit(scalerXtrain,Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1216\n",
      "           1       0.99      0.99      0.99       400\n",
      "\n",
      "    accuracy                           1.00      1616\n",
      "   macro avg       1.00      0.99      1.00      1616\n",
      "weighted avg       1.00      1.00      1.00      1616\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fb36a8c90d0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_labels = fitted.predict(scalerXtest)\n",
    "print(fitted.best_estimator_)\n",
    "print(classification_report(Ytest, pred_labels))\n",
    "ConfusionMatrixDisplay.from_estimator(fitted, scalerXtest, Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Question 5.1.1 (4 points):** Answer the following questions:\n",
    "\n",
    "1. The model had an accuracy of 100%, which means somethings wrong with my model I feel\n",
    "\n",
    "2. Not much better, 99% vs 100%. But i think I did something wrong with this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository! (2 points)**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"Committing Part 5\".\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part3\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "# Part 6. Regression Redux (7 Points)\n",
    "\n",
    "**&#9989; Question 6.1.1 (3 points):** Let's investigate the Logistic model again and see how it performs on the new PCA-transformed dataset. \n",
    "\n",
    "**Do this**: Make an Logistic model using the PCA features (2 features + constant). You should add a constant to the two PCA features, giving you three total features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logit_model2 = sm.Logit(train_labels2, sm.add_constant(train_vectors2))\n",
    "result = logit_model2.fit()\n",
    "print(result.summary() )\n",
    "const2 = sm.add_constant(test_vectors2)\n",
    "\n",
    "predicted2=logit_model2.predict(const2)\n",
    "predicted_labels2=list(map(round,predicted2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I dont know how I get inf or nans when i removed all of them at once in the begining on line 53, thats dumb what the hell is the dropna suppose to do then?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**&#9989; Question 6.1.2 (2 points):**  Examine the results by making a confusion matrix (2 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T03:37:45.505079Z",
     "start_time": "2022-12-07T03:37:45.503036Z"
    }
   },
   "source": [
    "\n",
    "cm2 = confusion_matrix(test_labels2, predicted_labels2)\n",
    "print (\"Confusion Matrix : \\n\", cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository! (2 points)**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"Committing Part 6\".\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"part7\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "# Part 7. Conceptual Questions (14 Points)\n",
    "\n",
    "**&#9989; Question 7.1 (4 points):** Compare your results from 3.2.2 and 6.1.2, two Logistic regression models that used the three most significant features. Which one performed better? Why? Your explanation should discuss the difference between the features in the two models and how that difference might affect how well the model fits the data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm assuming the model in 3.2.2 did because it had very high accuracy (92%). It also used features with the lowest SE, which means it had more reliable means. I counld't get 6.1.2 to work and I'm really annoyed, by the PCA model would have used probalties between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 7.2 \n",
    "The following questions probe your understanding of  `recall` and `precision`. You’ll be given a specific scenario, and you will need to decide whether to select a Machine Learning model that maximizes `recall` or `precision`.\n",
    "\n",
    "\n",
    "**&#9989; Question 7.2 (4 points):**  A new disease has been detected in Sweden. Doctors have taken multiple measurements of patients and passed them along to you. You’ve tested various models to predict which patients have the new disease. The Swedish health experts have told you it is critical that they identify **all** of the patients with the new disease so they can put them into quarantine. They tell you that it doesn’t matter if your model accidentally flags some people as having the disease even when they don’t, as it’s much better to tell people who aren’t sick to quarantine than to tell a sick person they don’t need to quarantine.\n",
    "\n",
    "Given this situation, should you choose the model that maximizes `recall` or the model that maximizes `precision`? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall, because it will consider false neagtives. If it lets false negatives go here, people could die, so precision is a bad choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**&#9989; Question 7.2.2 (4 points):**\n",
    "You are working for the state of Michigan, helping them with their new unemployment insurance program. You’ve created various models that are meant to detect fraud–i.e., determine whether or not someone applied for unemployment insurance when they shouldn’t have. Your boss tells you that it’s critical that your model doesn’t accidentally accuse an innocent person of fraud. They say it’s fine if your model misses some people who committed fraud as long as there are no false accusations. \n",
    "\n",
    "Given this situation, should you choose the model that maximizes `recall` or the model that maximizes `precision`? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision is best here, as the circumstances are reversed from the last example. You do not want false negatives to be relevant here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository!** (2 points)\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"Committing Part 7\".\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"conclusion\"></a>\n",
    "[Back to ToC](#toc)\n",
    "\n",
    "# Part 8. Conclusion (3 points)\n",
    "\n",
    "Make sure all of your changes to your repository are committed and pushed to GitHub. \n",
    "Before you leave\n",
    "\n",
    "1. Have you added your name and github username at the top of this notebook? ? (1 point)\n",
    "\n",
    "2. Push the changes to your GitHub repository (1 point)\n",
    "\n",
    "3. Upload your notebook to D2L in case something went wrong with your repository or if you couldn't get the repository to work.  (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You're done! Congrats on finishing your CMSE 202 Midterm!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T21:32:42.910515Z",
     "start_time": "2022-12-05T21:32:42.900046Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# FINAL GRADE (Instructor's use only)\",\n",
    "parts = [part_0, part_1, part_2, part_3, part_4, part_5, part_6, part_7]\n",
    "print(f\"Part 0: {part_0}/{grades[0]}\")\n",
    "print(f\"Part 1: {part_1}/{grades[1]}\")\n",
    "print(f\"Part 2: {part_2}/{grades[2]}\")\n",
    "print(f\"Part 3: {part_3}/{grades[3]}\")\n",
    "print(f\"Part 4: {part_4}/{grades[4]}\")\n",
    "print(f\"Part 5: {part_5}/{grades[5]}\")\n",
    "print(f\"Part 6: {part_6}/{grades[6]}\")\n",
    "print(f\"Part 7: {part_7}/{grades[7]}\")\n",
    "\n",
    "total = sum(parts)\n",
    "print(f\"Your final grade is {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#169; Copyright 2022,  Department of Computational Mathematics, Science and Engineering at Michigan State University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
